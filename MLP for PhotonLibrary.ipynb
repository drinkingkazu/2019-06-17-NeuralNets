{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP for PhotonLibrary.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnDIXQNtDHw-",
        "colab_type": "text"
      },
      "source": [
        "# PhotonLibrary + MLP\n",
        "**This notebook: [see on github](https://github.com/drinkingkazu/2019-06-17-Notebooks/blob/master/MLP%20for%20PhotonLibrary.ipynb) or [run it on google colab](https://colab.research.google.com/github/drinkingkazu/2019-06-17-Notebooks/blob/master/MLP%20for%20PhotonLibrary.ipynb)**.\n",
        "\n",
        "A photon library is a look-up map for a LArTPC detector. Provided (x,y,z) position, a photon library provides a probability of detecting a photon by individual PMT. Why do we use a photon library? Because simulation of individual photon propagation requires ray tracing, and it is hard to use a parametric function for approximation due to stochastic physics processes (scattering) and often a complicated detector geometry (field cage, anode wires, cryostat, etc.). A downside of using a photon library is the memory as it needs to hold infomration of probability per PMT (floating point value * PMT counts) for every single voxelized volume in the detector.\n",
        "\n",
        "An alternative method to a photon library is a neural network, which is good at function approximation. This notebook is an attempt to emulate a photon library with MLP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-rtSfv4DHxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "011085af-76d1-42a1-d29f-1be8ae69a763"
      },
      "source": [
        "from __future__ import print_function\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import numpy as np\n",
        "SEED=123\n",
        "_=np.random.seed(SEED)\n",
        "_=torch.manual_seed(SEED)\n",
        "\n",
        "! [ -d kworkshop ] || git clone -b 2019-06-17-NeuralNets https://github.com/drinkingkazu/kworkshop\n",
        "! cd kworkshop && git pull && cd -"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzXKX86RDHxR",
        "colab_type": "text"
      },
      "source": [
        "Instantiate a photon library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj0Ay6CeDHxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from kworkshop.utils import PhotonLibrary\n",
        "plib=PhotonLibrary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOsuTMG1I1s_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c92726aa-a7d4-4557-dfe8-de1396d7b606"
      },
      "source": [
        "class dataset:\n",
        "  \n",
        "  def __init__(self,plib,num_points=10000):\n",
        "    self._plib = plib\n",
        "    self._num_points = num_points\n",
        "    \n",
        "  def __len__(self):\n",
        "    return 100000\n",
        "  \n",
        "  def __getitem__(self,index):\n",
        "    return self.random_points(self._num_points)\n",
        "  \n",
        "  def random_points(self, num_points):\n",
        "  \n",
        "    points = np.zeros(shape=(num_points,3), dtype=np.float32)\n",
        "    ranges = (self._plib.XRange(), self._plib.YRange(), self._plib.ZRange())\n",
        "\n",
        "    for index, r in enumerate(ranges):\n",
        "      points[:,index] = r[0] + (r[1]-r[0]) * np.random.ranf(num_points)\n",
        "\n",
        "    voxel_ids = [ self._plib.GetVoxelID(pt[0], pt[1], pt[2]) for pt in points ]\n",
        "    for i, vox in enumerate(voxel_ids):\n",
        "      if vox > self._plib._plib.shape[1]:\n",
        "        print(vox,points[i][0],points[i][1],points[i][2])\n",
        "\n",
        "    visibility = np.array([ [ self._plib._plib[pmt][voxel] for pmt in range(180) ] for voxel in voxel_ids ])\n",
        "    visibility = visibility.astype(np.float32)\n",
        "\n",
        "    return points, visibility\n",
        "  \n",
        "d = dataset(plib)\n",
        "d.random_points(100)[0].shape\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MMEi58nI3se",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "plib_dataset = dataset(plib,num_points=1000)\n",
        "loader       = DataLoader(plib_dataset, batch_size=4, num_workers=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld2Y9KtdLsBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "ecdfcff4-9527-496e-c319-0166723e6586"
      },
      "source": [
        "import time\n",
        "\n",
        "t0=time.time()\n",
        "for index, data in enumerate(loader):\n",
        "  t1=time.time()\n",
        "  print('Batch',index,'Time',t1-t0)\n",
        "  t0=time.time()\n",
        "  \n",
        "  if index==39: break\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 0 Time 8.188227653503418\n",
            "Batch 1 Time 0.0003170967102050781\n",
            "Batch 2 Time 0.6615324020385742\n",
            "Batch 3 Time 0.00037384033203125\n",
            "Batch 4 Time 0.0003077983856201172\n",
            "Batch 5 Time 0.0003082752227783203\n",
            "Batch 6 Time 0.02953195571899414\n",
            "Batch 7 Time 0.09671759605407715\n",
            "Batch 8 Time 0.0003685951232910156\n",
            "Batch 9 Time 0.0003478527069091797\n",
            "Batch 10 Time 0.0003204345703125\n",
            "Batch 11 Time 0.0003249645233154297\n",
            "Batch 12 Time 0.00034999847412109375\n",
            "Batch 13 Time 0.0003459453582763672\n",
            "Batch 14 Time 0.01885390281677246\n",
            "Batch 15 Time 0.0003266334533691406\n",
            "Batch 16 Time 5.00968337059021\n",
            "Batch 17 Time 0.6126365661621094\n",
            "Batch 18 Time 0.0003592967987060547\n",
            "Batch 19 Time 0.12052559852600098\n",
            "Batch 20 Time 0.00038170814514160156\n",
            "Batch 21 Time 0.0003192424774169922\n",
            "Batch 22 Time 0.00035834312438964844\n",
            "Batch 23 Time 0.00038814544677734375\n",
            "Batch 24 Time 0.14615488052368164\n",
            "Batch 25 Time 0.0003905296325683594\n",
            "Batch 26 Time 0.0003135204315185547\n",
            "Batch 27 Time 0.00036978721618652344\n",
            "Batch 28 Time 0.00033020973205566406\n",
            "Batch 29 Time 0.0003829002380371094\n",
            "Batch 30 Time 0.0003795623779296875\n",
            "Batch 31 Time 0.0003616809844970703\n",
            "Batch 32 Time 5.211659669876099\n",
            "Batch 33 Time 0.13761329650878906\n",
            "Batch 34 Time 0.19411921501159668\n",
            "Batch 35 Time 0.0003781318664550781\n",
            "Batch 36 Time 0.00032973289489746094\n",
            "Batch 37 Time 0.0003662109375\n",
            "Batch 38 Time 0.00038743019104003906\n",
            "Batch 39 Time 0.00038933753967285156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUvrbhfH1F7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        \n",
        "        super(MLP, self).__init__()        \n",
        "        # MLP w/ 2 hidden layers, 1024 neurons each\n",
        "        self._estimator = torch.nn.Sequential(\n",
        "            torch.nn.Linear(3,   1024), torch.nn.ReLU(),\n",
        "            torch.nn.Linear(1024,1024), torch.nn.ReLU(),\n",
        "            torch.nn.Linear(1024,180),  torch.nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._estimator(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxVdmCdr0OUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BLOB:\n",
        "    pass\n",
        "blob=BLOB()\n",
        "blob.net       = MLP().cuda() # construct Lenet, use GPU\n",
        "blob.criterion = torch.nn.SmoothL1Loss() # use Huber loss to define an error\n",
        "blob.optimizer = torch.optim.Adam(blob.net.parameters()) # use Adam optimizer algorithm\n",
        "blob.iteration = 0    # integer count for the number of train steps\n",
        "blob.data      = None # data for training/analysis\n",
        "blob.label     = None # label for training/analysis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANwIjxeML76t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(blob,train=True):\n",
        "    \"\"\"\n",
        "       Args: blob should have attributes, net, criterion, softmax, data, label\n",
        "       \n",
        "       Returns: a dictionary of predicted labels, softmax, loss, and accuracy\n",
        "    \"\"\"\n",
        "    with torch.set_grad_enabled(train):\n",
        "        # Prediction\n",
        "        data = blob.data.cuda()\n",
        "        prediction = blob.net(data)\n",
        "        # Training\n",
        "        loss,acc=-1,-1\n",
        "        if blob.label is not None:\n",
        "            label = blob.label.cuda()\n",
        "            loss = blob.criterion(prediction,label)\n",
        "            \n",
        "        blob.loss = loss\n",
        "        \n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "        \n",
        "        return {'prediction' : prediction,\n",
        "                'loss'       : loss.cpu().detach().item()}\n",
        "      \n",
        "def backward(blob):\n",
        "    blob.optimizer.zero_grad()  # Reset gradients accumulation\n",
        "    blob.loss.backward()\n",
        "    blob.optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R4qwN6v0TjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_loop(blob,train_loader,num_iteration):\n",
        "    # Set the network to training mode\n",
        "    blob.net.train()\n",
        "    # Let's record the loss at each iteration and return\n",
        "    train_loss=[]\n",
        "    # Loop over data samples and into the network forward function\n",
        "    for i,data in enumerate(train_loader):\n",
        "        if blob.iteration >= num_iteration:\n",
        "            break\n",
        "        blob.iteration += 1\n",
        "        # data and label\n",
        "        blob.data, blob.label = data\n",
        "        # call forward\n",
        "        res = forward(blob,True)\n",
        "        # Recird loss\n",
        "        train_loss.append(res['loss'])\n",
        "        # once in a while, report\n",
        "        if blob.iteration == 0 or (blob.iteration+1)%10 == 0:\n",
        "            print('Iteration',blob.iteration,'... Loss',res['loss'])\n",
        "        backward(blob)\n",
        "    return np.array(train_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNOV0bVt1fo_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "4cb1aebd-e141-461b-bed5-0843537b2f8e"
      },
      "source": [
        "loss = train_loop(blob,loader,100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 9 ... Loss 3.2338798519049305e-06\n",
            "Iteration 19 ... Loss 5.071385658084182e-06\n",
            "Iteration 29 ... Loss 5.071385658084182e-06\n",
            "Iteration 39 ... Loss 4.1226480789191555e-06\n",
            "Iteration 49 ... Loss 5.713039172405843e-06\n",
            "Iteration 59 ... Loss 5.713039172405843e-06\n",
            "Iteration 69 ... Loss 5.469317784445593e-06\n",
            "Iteration 79 ... Loss 5.469317784445593e-06\n",
            "Iteration 89 ... Loss 3.724443331520888e-06\n",
            "Iteration 99 ... Loss 5.1737119974859525e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWY1EaoE6Ru-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "de974923-cf04-46c7-a87a-35b3feba8a9d"
      },
      "source": [
        "fig,ax=plt.subplots(figsize=(12,8),facecolor='w')\n",
        "plt.plot(range(len(loss)),loss,marker=\"\",linewidth=2,color='blue')\n",
        "from kworkshop.utils import moving_average \n",
        "plt.plot(moving_average(range(len(loss)),30),moving_average(loss,30),marker=\"\",linewidth=2,color='red')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-20056d3ec612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkworkshop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoving_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmoving_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    }
  ]
}